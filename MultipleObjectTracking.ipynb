{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "MultipleObjectTracking.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cce0101-2458-4970-b242-3b85e000e0a8"
      },
      "source": [
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from imageai.Detection import ObjectDetection\n",
        "import requests as req\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "import os\n",
        "from random import randint\n",
        "from glob import glob"
      ],
      "id": "7cce0101-2458-4970-b242-3b85e000e0a8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa48361b-828c-43cf-8692-b1460bfe2478"
      },
      "source": [
        "if not os.path.exists('output'):\n",
        "    os.makedirs('output')"
      ],
      "id": "aa48361b-828c-43cf-8692-b1460bfe2478",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed749819-331c-40be-884b-2b4b4e8a38f5"
      },
      "source": [
        "# Function to get download model\n",
        "def getModel():    \n",
        "    model_url = 'https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/yolo.h5'\n",
        "    if not os.path.exists('yolo.h5'):\n",
        "        r = req.get(model_url, timeout=0.5)\n",
        "        with open('yolo.h5', 'wb') as outfile:\n",
        "            outfile.write(r.content)"
      ],
      "id": "ed749819-331c-40be-884b-2b4b4e8a38f5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "719a010a-e7f6-4c54-993c-27769de3645f"
      },
      "source": [
        "#getModel()"
      ],
      "id": "719a010a-e7f6-4c54-993c-27769de3645f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daf8feb4-5650-493f-94de-b416010bf5f5"
      },
      "source": [
        "# load Model\n",
        "def loadModel():\n",
        "    execution_path = os.getcwd()\n",
        "\n",
        "    detector = ObjectDetection()\n",
        "    detector.setModelTypeAsYOLOv3()\n",
        "    detector.setModelPath( os.path.join(execution_path , \"yolo.h5\"))\n",
        "    detector.loadModel()\n",
        "    peopleOnly = detector.CustomObjects(person=True)\n",
        "    return detector, peopleOnly\n",
        "\n"
      ],
      "id": "daf8feb4-5650-493f-94de-b416010bf5f5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0276e4ba-f07e-49a9-8518-9328c8aaa74c"
      },
      "source": [
        "trackerTypes = ['KCF', 'CSRT']\n",
        "\n",
        "def createTracker(trackerType):\n",
        "    if trackerType == trackerTypes[0]:\n",
        "        tracker = cv2.TrackerKCF_create()\n",
        "    elif trackerType == trackerTypes[1]:\n",
        "        tracker = cv2.TrackerCSRT_create()\n",
        "    else:\n",
        "        tracker = None\n",
        "        print('Incorrect tracker name')\n",
        "        print('Available trackers are:')\n",
        "        for t in trackerTypes:\n",
        "            print(t)\n",
        "\n",
        "    return tracker"
      ],
      "id": "0276e4ba-f07e-49a9-8518-9328c8aaa74c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a82a0894-c8d1-40fd-9cd7-b6e1d4a96b4a"
      },
      "source": [
        "# loadind model\n",
        "detector, peopleOnly = loadModel()"
      ],
      "id": "a82a0894-c8d1-40fd-9cd7-b6e1d4a96b4a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d775912-c047-4acc-a595-4cd72d743a4f"
      },
      "source": [
        "\n",
        "\n",
        "# function to to detect objects with bounding box\n",
        "def detection(image, detector=detector, detection_objects=peopleOnly):\n",
        "    detectedImage, detections = detector.detectObjectsFromImage(custom_objects=detection_objects,\n",
        "                                                            input_type=\"array\", \n",
        "                                                            input_image=image, \n",
        "                                                            output_type = \"array\",\n",
        "                                                            minimum_percentage_probability=30)\n",
        "    BBoxes = []\n",
        "    colors = []\n",
        "    for BBox in detections:\n",
        "        BBoxes.append((BBox[\"box_points\"][0], \n",
        "                       BBox[\"box_points\"][1], \n",
        "                       int(BBox[\"box_points\"][2]-BBox[\"box_points\"][0]), \n",
        "                       int(BBox[\"box_points\"][3]-BBox[\"box_points\"][1])))\n",
        "        colors.append(((randint(64, 255), randint(64, 255), randint(64, 255))))\n",
        "    return BBoxes, colors\n",
        "    \n"
      ],
      "id": "9d775912-c047-4acc-a595-4cd72d743a4f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab818248-3e76-43e6-b219-c47cd890235d"
      },
      "source": [
        "def cross(p1,p2,p3): # Cross product judgment\n",
        "    x1=p2[0]-p1[0]\n",
        "    y1=p2[1]-p1[1]\n",
        "    x2=p3[0]-p1[0]\n",
        "    y2=p3[1]-p1[1]\n",
        "    return x1*y2-x2*y1  \n",
        "\n",
        "\n",
        "#Determine whether the two line segments intersect\n",
        "def segment(p1,p2,p3,p4): \n",
        "  \n",
        "    if(max(p1[0],p2[0])>=min(p3[0],p4[0]) \n",
        "    and max(p3[0],p4[0])>=min(p1[0],p2[0]) \n",
        "    and max(p1[1],p2[1])>=min(p3[1],p4[1]) \n",
        "    and max(p3[1],p4[1])>=min(p1[1],p2[1])): \n",
        "        if(cross(p1,p2,p3)*cross(p1,p2,p4)<=0  \n",
        "            and cross(p3,p4,p1)*cross(p3,p4,p2)<=0):\n",
        "            D=1\n",
        "        else:\n",
        "            D=0\n",
        "    else:\n",
        "        D=0\n",
        "    return D\n",
        "\n",
        "def check(l1,l2,sq):\n",
        "    # step 1 check if end point is in the square\n",
        "    if ( l1[0] >= sq[0] and l1[1] >= sq[1] and  l1[0] <= sq[2] and  l1[1] <= sq[3]) or ( l2[0] >= sq[0] and l2[1] >= sq[1] and  l2[0] <= sq[2] and  l2[1] <= sq[3]):\n",
        "        return 1\n",
        "    else:\n",
        "        # step 2 check if diagonal cross the segment\n",
        "        p1 = [sq[0],sq[1]]\n",
        "        p2 = [sq[2],sq[3]]\n",
        "        p3 = [sq[2],sq[1]]\n",
        "        p4 = [sq[0],sq[3]]\n",
        "        if segment(l1,l2,p1,p2) or segment(l1,l2,p3,p4):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0"
      ],
      "id": "ab818248-3e76-43e6-b219-c47cd890235d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42068d8a-3421-4c8c-b02c-f847600dd015"
      },
      "source": [
        "def objectTracker(filename, p1, p2):\n",
        "    \n",
        "    tracker = cv2.TrackerCSRT_create()\n",
        "    video = cv2.VideoCapture(filename)\n",
        "    ret, frame = video.read()\n",
        "    token = filename.split(\"\\\\\")\n",
        "    outputFilename = \"output\\\\output_\"+token[-1]\n",
        "    bboxes, colors = detection(frame)\n",
        "    frame_width = int(video.get(3))\n",
        "    frame_height = int(video.get(4))\n",
        "    # I am using major version 4 though\n",
        "    (major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
        "    if int(major_ver)  < 3 :\n",
        "        fps = video.get(cv2.cv.CV_CAP_PROP_FPS)\n",
        "    else :\n",
        "        fps = video.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    size = (frame_width, frame_height)\n",
        "    \n",
        "    multiTracker = cv2.MultiTracker_create()\n",
        "    for bbox in bboxes:\n",
        "        multiTracker.add(createTracker('CSRT'), frame, bbox)\n",
        "        \n",
        "        \n",
        "    out = cv2.VideoWriter(outputFilename,  cv2.VideoWriter_fourcc(*'XVID'), fps, size)\n",
        "    \n",
        "    items = []\n",
        "    record = []\n",
        "    frame_count = 0    \n",
        "    while True:\n",
        "        ret, frame = video.read()\n",
        "        cv2.namedWindow('Tracking', cv2.WINDOW_NORMAL)\n",
        "        frame_count += 1 \n",
        "        if not ret:\n",
        "            break\n",
        "        ret, boxes = multiTracker.update(frame)\n",
        "        \n",
        "        \n",
        "        for i, newbox in enumerate(boxes):\n",
        "            p1 = (int(newbox[0]), int(newbox[1]))\n",
        "            p2 = (int(newbox[0] + newbox[2]), int(newbox[1] + newbox[3]))\n",
        "            cv2.rectangle(frame, p1, p2, colors[i], 2, 1)\n",
        "            \n",
        "            if i not in items:\n",
        "                crossFlag = check(p1, p2, newbox)\n",
        "                if crossFlag==1:\n",
        "                    items.append(i)\n",
        "                    (x, y, w, h) = [int(v) for v in newbox]\n",
        "                    \n",
        "                    time = frame_count/fps\n",
        "                    \n",
        "                    image = frame[y:y+h, x:x+w]\n",
        "                    imagename = \"output\\\\\"+token[-1]+\"Person_\"+str(i)+\".png\"\n",
        "                    cv2.imwrite(imagename, image)\n",
        "                    dict_data = {\"id\":i,\"time\":str(time)}\n",
        "                    record.append(dict_data)\n",
        "        \n",
        "        cv2.line(frame, p1, p2, (255,0,0), 12, lineType = 8, shift = 0)\n",
        "        cv2.resizeWindow('Tracking', int(frame_width*0.5), int(frame_height*0.5))\n",
        "        out.write(frame)\n",
        "        cv2.imshow('Tracking', frame)\n",
        "        if cv2.waitKey(1) & 0XFF ==27: # ESC\n",
        "            break\n",
        "    \n",
        "    savepath = \"output\\\\\"+token[-1]+\".json\"\n",
        "    with open(savepath, 'w') as f:\n",
        "        json.dump(record, f)\n",
        "          \n",
        "    video.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "        \n",
        "       \n",
        "    \n",
        "    \n",
        "    "
      ],
      "id": "42068d8a-3421-4c8c-b02c-f847600dd015",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c1d97ee-f852-4517-9ee9-85ba2688d6c2"
      },
      "source": [
        ""
      ],
      "id": "2c1d97ee-f852-4517-9ee9-85ba2688d6c2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb89bc92-1f31-4401-895a-08721782612c"
      },
      "source": [
        "fileLists = glob(\"videos\\*.mp4\")\n",
        "for path in fileLists:\n",
        "    objectTracker(path, (0,20), (0,2000))\n",
        "    "
      ],
      "id": "cb89bc92-1f31-4401-895a-08721782612c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "211b0e83-5e5e-44c6-8cfd-a86c25036aa2"
      },
      "source": [
        "##### **Refrence**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   [codeproject](https://www.codeproject.com/Articles/5270240/Using-Pretrained-Models-to-Detect-People-With-Open)\n",
        "*   [imageai](https://imageai.readthedocs.io/en/latest/video/)\n",
        "*   [programmersought](https://programmersought.com/article/92505648677/)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "211b0e83-5e5e-44c6-8cfd-a86c25036aa2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6eb8729-cc37-41cf-99fd-ccc4c3a56a0a"
      },
      "source": [
        ""
      ],
      "id": "b6eb8729-cc37-41cf-99fd-ccc4c3a56a0a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10fcdfdb-cf20-4cf4-aeba-f1bd9d08b138"
      },
      "source": [
        ""
      ],
      "id": "10fcdfdb-cf20-4cf4-aeba-f1bd9d08b138",
      "execution_count": null,
      "outputs": []
    }
  ]
}